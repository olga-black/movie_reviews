{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:turquoise\">Text classification with pytorch</span>\n",
    "\n",
    "\n",
    "An example of using natural language processing for sentiment analysis. <br> Building a binary classifier of movie reviews that will predict if a review is positive or negative.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__Dataset:__ IMDB movie reviews from Kaggle<br>\n",
    "__Model:__ LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:teal\">Todo:</span>\n",
    "\n",
    "- ~~Read dataset~~\n",
    "- ~~Preprocess text~~\n",
    "- ~~Split into train, validation, and test sets~~\n",
    "- ~~Convert text to indices and add paddings~~\n",
    "- ~~Make model~~\n",
    "- ~~Make training function~~\n",
    "- ~~Make evaluation function~~\n",
    "- ~~Train~~\n",
    "- Evaluate on test set\n",
    "- Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:teal\">Read the data and split it into training, cross-validation, and test sets</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reviews():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train = {}\n",
    "        self.val = {}\n",
    "        self.test = {}\n",
    "        self.LABELS = {\"positive\":1, \"negative\": 0}\n",
    "        self.COUNT = {\"positive\": 0, \"negative\": 0}\n",
    "    \n",
    "    \n",
    "    def read_data(self):\n",
    "        \n",
    "        dataset = []\n",
    "        \n",
    "        with open (\"IMDB_Dataset.csv\", newline='') as f:\n",
    "            datareader = csv.reader(f, delimiter=',')\n",
    "            next(datareader, None)\n",
    "\n",
    "            for row in datareader:\n",
    "                dataset.append([row[0], self.LABELS[row[1]]])\n",
    "                self.COUNT[row[1]] += 1\n",
    "            \n",
    "            random.shuffle(dataset)\n",
    "                \n",
    "        return dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def split_dataset(self,\n",
    "                      dataset,\n",
    "                      split=[int(50000*0.6), int(50000*0.2), int(50000*0.2)]):\n",
    "        \n",
    "        train, val, test = torch.utils.data.random_split(dataset,\n",
    "                                               split,\n",
    "                                               generator=torch.Generator().manual_seed(43))\n",
    "          \n",
    "            \n",
    "        return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = Reviews()\n",
    "data = rev.read_data()\n",
    "pos_count = rev.COUNT[\"positive\"]\n",
    "neg_count = rev.COUNT[\"negative\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Its a very good comedy movie.Ijust liked it.I don't know why i love this movie i just love it.Storyline:It is a story of two boys Amar (Aamir Khan) and Prem (Salman Khan) who want to get rich quickly by taking all the short-cuts in the book. Amar is the son of an honest barber, Murli Manohar (Deven Verma) in Mumbai, while Prem is the son of Bankeylal Bhopali (Jagdeep), a hardworking tailor in Bhopal. Both Amar and Prem sell their father's shop and house respectively, and zero in on a hill station where a beautiful wealthy heiress Raveena (Raveena Tandon) has come from London accompanied by her friend cum secretary Karishma (Karishma Kapoor) with the intention of getting married to a virtuous Indian. The lucky man to wed Raveena will inherit her father Ram Gopal Bajaj's (Paresh Rawal) entire wealth. Amar and Prem see their get rich quick chance and woo Raveena, each trying to out do the other. Enter Teja (Paresh Rawal in a double role) whose sole ambition in life has been to grab his twin brother Ram Gopal Bajaj's millions. So Teja plants Bhalla. (Shehzad) and Robert (Vijoo Khote) in Raveena's house, to help him in fulfill his ambition. As the story progresses it turns out to be a mad chase from Ram Gopal Bajaj's wealth, full of humor, romance thrills and chills. Will Raveena & Karishma see through Amar and Prem's mischievous intentions? Will Teja succeed in his motives? See it all in super comedy ANDAZ APNA APNA.  and very good Comedy !!!!!!\", 1]\n"
     ]
    }
   ],
   "source": [
    "print(data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"THE MATADOR is hit-man movie lite....if you can say that about a hit-man movie. The violence is never really shown but often introduced. At first I was scared I was in for another retread of mid-90s gangster-hit-man-hipster-dark comedy BUT was happily surprised when I realized this is just a sweet and humorous story about friendship. Nothing terribly exciting happens in this film but every bit of it is kept me grinning. The three leads have the best chemistry the big screen has offered in recent years and it looks like they had a great time making this film together. The writing is sharp though at times it felt as if the script had been adapted from a stage play because of the one set dialog scenes. This is a good film that I probably won't remember for too long but at the time it was a complete joy. Good film.\", 1]\n"
     ]
    }
   ],
   "source": [
    "train, val, test = rev.split_dataset(data)\n",
    "print(train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_x_and_y(data):\n",
    "    x = []\n",
    "    y = []\n",
    "    for review, label in data:\n",
    "        x.append(review)\n",
    "        y.append(label)\n",
    "    return x, np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000\n",
      "While in one country, Spain, Luis Bunuel and Salvador Dali combined forces to create the benchmark of short-subject, cinematic surrealism, Un Chien Andalou, Walt Disney and his collaborator Ub Iwerks in America worked on Steamboat Willie, the most prominent of the early synchronized sound cartoons (it was revealed that this was not the first, contrary to other reports). It's also one of the more successfully simplistic and funny of the Mickey Mouse shorts (still in a silent-film way- the only sounds are little irks and bleeps from the Mickey and the animals). It also goes by fairly quickly for its less-than-ten minute run. But in these minutes one gets the immediate sense of how much fun Disney has with his characters, and how the newfound use of sound changes how his creation uses the animals as musical tools. There's no story to speak of, just random things that happens and occurs because of Mickey (err, Steamboat Willie) on this boat on a river. And like the better Mickey Mouse shorts, his lack of speaking acts as an advantage. It's a must-see if you haven't seen it as a kid, but if you have it might still be worth another look. 1\n"
     ]
    }
   ],
   "source": [
    "train_x_raw, train_y = split_x_and_y(train)\n",
    "val_x_raw, val_y = split_x_and_y(val)\n",
    "test_x_raw, test_y = split_x_and_y(test)\n",
    "\n",
    "\n",
    "print(len(train_x_raw), len(train_y))\n",
    "print(train_x_raw[50], train_y[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:teal\">Preprocess text</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(review,\n",
    "               remove_stopwords=False, \n",
    "               remove_html=True, \n",
    "               remove_punct=False, \n",
    "               lowercase=False, \n",
    "               lemmatize=False,\n",
    "               maxlen=128):\n",
    "    \n",
    "    review = re.sub(r\"\\'\", \"'\", review)\n",
    "    review = re.sub(r\"\\x96\", \"-\", review)\n",
    "    \n",
    "    if remove_html:\n",
    "        review = re.sub(r'<.*>', ' ', review)\n",
    "    \n",
    "    review = word_tokenize(review)\n",
    "        \n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        review = [w for w in review if w not in stop_words]\n",
    "        \n",
    "    if remove_punct:\n",
    "        contractions = [\"'ll\", \"'s\", \"n't\", \"'d\", \"'m\", \"'ve\", \"'re\"]\n",
    "        review = [w for w in review if w.isalnum() or w in contractions]\n",
    "    \n",
    "    if lowercase:\n",
    "        review = [w.lower() for w in review]\n",
    "        \n",
    "    if lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        review = [lemmatizer.lemmatize(w) for w in review]\n",
    "    \n",
    "    \n",
    "    return review[:maxlen]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = [preprocess(review, \n",
    "                      lowercase=True, \n",
    "                      remove_punct=True,\n",
    "                      remove_stopwords=True\n",
    "                     ) \n",
    "           for review in train_x_raw]\n",
    "\n",
    "val_words = [preprocess(review, \n",
    "                    lowercase=True, \n",
    "                    remove_punct=True,\n",
    "                    remove_stopwords=True\n",
    "                   ) \n",
    "         for review in val_x_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'movie', 'great', 'venezuelan', 'tourism', 'birds', 'birds', 'birds', 'only', '1', 'piranha', 'nice', 'scenery', 'the', 'highlight', 'alligator', 'seen', 'long', 'boring', 'motorcycle', 'race', 'the', 'end', 'caribe', 'drowns', 'definite', 'hollywood', 'prop', 'there', 'definite', 'storyline', 'it', 'goes', 'venezuelan', 'scenery', 'rip', 'easy', 'rider', 'diamond', 'mining', 'ruthless', 'hunter', 'going', 'crazy', 'reason', 'gets', 'end', 'a', 'low', 'budget', 'movie', 'could', 'filmed', 'anywhere', 'outtakes', 'venezuela', 'william', 'smith', 'talented', 'actor', 'made', 'good', 'movies', 'like', 'actors', 'need', 'least', 'one', 'bad', 'film', 'do', \"n't\", 'waste', 'dvd'] \n",
      " ['the', 'claude', 'lelouch', \"'s\", 'movie', 'pretty', 'good', 'moment', 'cinema', 'one', 'touching', 'films', 'family', 'loneliness', 'surely', 'best', 'interpretation', 'french', 'actor', 'belmondo']\n",
      "74 \n",
      " 20\n"
     ]
    }
   ],
   "source": [
    "print(train_words[9592], '\\n', val_words[3029])\n",
    "print(len(train_words[9592]), '\\n', len(val_words[3029]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:teal\">Convert text to indices and add paddings</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vocabulary_dicts(preprocessed_data, pad_token='<PAD>', unk_token='<UNK>'):\n",
    "    vocab = set()\n",
    "    \n",
    "    for review in preprocessed_data:\n",
    "        for word in review:\n",
    "            vocab.add(word)\n",
    "    \n",
    "            \n",
    "    vocab_sorted = sorted(vocab)\n",
    "    word2ind = {word : i+2 for i, word in enumerate(vocab_sorted)}\n",
    "    ind2word = {i+2 : word for i, word in enumerate(vocab_sorted)}\n",
    "    \n",
    "    # Prepend the pad token\n",
    "    word2ind[pad_token] = 0\n",
    "    ind2word[0] = pad_token\n",
    "    \n",
    "    # Prepend the 'unknown' token\n",
    "    word2ind[unk_token] = 1\n",
    "    ind2word[1] = unk_token\n",
    "    \n",
    "    assert len(word2ind) == len(ind2word)\n",
    "\n",
    "    \n",
    "    return word2ind, ind2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_x_raw, val_x_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61552 61552\n",
      "37504 4183\n",
      "bone clockwise\n"
     ]
    }
   ],
   "source": [
    "word2ind, ind2word = make_vocabulary_dicts(train_words)\n",
    "\n",
    "print(len(word2ind), len(ind2word))\n",
    "print(word2ind['never'], word2ind['awful'])\n",
    "print(ind2word[6700], ind2word[10582])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "71.35953333333333\n",
      "128\n",
      "71.5128\n"
     ]
    }
   ],
   "source": [
    "print(np.max([len(x) for x in train_words]))\n",
    "print(np.mean([len(x) for x in train_words]))\n",
    "\n",
    "print(np.max([len(x) for x in val_words]))\n",
    "print(np.mean([len(x) for x in val_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_padded_inputs(preprocessed_data, \n",
    "                       vocab, \n",
    "                       padded_length=128,\n",
    "                       pad_token='<PAD>',\n",
    "                       unk_token='<UNK>'\n",
    "                      ):\n",
    "    \n",
    "    num_lines = len(preprocessed_data)\n",
    "    pad = vocab[pad_token]\n",
    "    \n",
    "    inputs = np.full((num_lines, padded_length), pad)\n",
    "    \n",
    "    for i, review in enumerate(preprocessed_data):\n",
    "        for j, word in enumerate(review):    \n",
    "            inputs[i, j] = vocab.get(word, vocab[unk_token])\n",
    "            \n",
    "    return inputs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example at index 10:\n",
      "['the', 'matador', 'movie', 'lite', 'say', 'movie', 'the', 'violence', 'never', 'really', 'shown', 'often', 'introduced', 'at', 'first', 'i', 'scared', 'i', 'another', 'retread', 'comedy', 'but', 'happily', 'surprised', 'i', 'realized', 'sweet', 'humorous', 'story', 'friendship', 'nothing', 'terribly', 'exciting', 'happens', 'film', 'every', 'bit', 'kept', 'grinning', 'the', 'three', 'leads', 'best', 'chemistry', 'big', 'screen', 'offered', 'recent', 'years', 'looks', 'like', 'great', 'time', 'making', 'film', 'together', 'the', 'writing', 'sharp', 'though', 'times', 'felt', 'script', 'adapted', 'stage', 'play', 'one', 'set', 'dialog', 'scenes', 'this', 'good', 'film', 'i', 'probably', 'wo', \"n't\", 'remember', 'long', 'time', 'complete', 'joy', 'good', 'film']\n",
      "\n",
      "    Converted to indices:\n",
      "[54695 34131 36447 32196 47544 36447 54695 58837 37504 44369 49327 38607\n",
      " 28354  3761 20409 26724 47620 26724  2776 45667 11084  8038 24587 53309\n",
      " 26724 44363 53514 26513 52321 21520 38058 54538 18895 24582 20222 18736\n",
      "  6055 30044 23722 54695 54938 31444  5693  9734  5857 48001 38575 44484\n",
      " 61009 32504 31982 23567 55149 33387 20222 55349 54695 60759 48899 54903\n",
      " 55164 19952 48040  1244 51698 41518 38769 48625 15014 47676 54866 23161\n",
      " 20222 26724 42729 60434 36919 45116 32465 55149 11311 29448 23161 20222\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_x = make_padded_inputs(train_words, word2ind)\n",
    "val_x = make_padded_inputs(val_words, word2ind)\n",
    "\n",
    "\n",
    "print(f\"\"\"Training example at index 10:\\n{train_words[10]}\\n\n",
    "    Converted to indices:\\n{train_x[10, :]}\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:teal\">Load data into torch</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "val_dataset = torch.utils.data.TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 vocab_size, \n",
    "                 d_feature, \n",
    "                 num_layers, \n",
    "                 hidden_size,\n",
    "                 n_outputs,\n",
    "                 bidirectional=False,\n",
    "                 dropout_rate=0.2):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, d_feature)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.lstm = nn.LSTM(input_size=d_feature,\n",
    "                           hidden_size=hidden_size,\n",
    "                           num_layers=num_layers,\n",
    "                           bidirectional=bidirectional,\n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, n_outputs)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, input_data): \n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input_data))\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        fc = self.fc(lstm_out[:,-1,:])\n",
    "        sigmoid = self.sigmoid(fc)\n",
    "   \n",
    "        return sigmoid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentClassifier(\n",
      "  (embedding): Embedding(61552, 128)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (lstm): LSTM(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2ind)\n",
    "d_feature = 128\n",
    "hidden_size = 128\n",
    "n_outputs = 1\n",
    "num_layers = 1\n",
    "\n",
    "model = SentimentClassifier(\n",
    "                            vocab_size=vocab_size, \n",
    "                            d_feature=d_feature,  \n",
    "                            num_layers=num_layers, \n",
    "                            hidden_size=hidden_size, \n",
    "                            n_outputs=n_outputs).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:teal\">Train model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader=train_loader,\n",
    "             val_loader=val_loader,\n",
    "             model=model,\n",
    "             optimizer=torch.optim.Adam(model.parameters(), lr=0.005),\n",
    "             criterion=nn.BCELoss(),\n",
    "             n_epochs=6):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:  \n",
    "            model.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "           \n",
    "        model.eval()\n",
    "            \n",
    "        val_losses = []\n",
    "        \n",
    "        \n",
    "        for val_inputs, val_labels in val_loader:\n",
    "\n",
    "            val_output = model(val_inputs)\n",
    "            val_loss = criterion(val_output.squeeze(), val_labels.float())\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "        \n",
    "        print(f\"Epoch: {epoch+1}/{ n_epochs}\".format(),\n",
    "              f\"Time taken: {((time.time() - start_time) / 60):.2f} min\",\n",
    "              f\"Training Loss: {loss.item():.4f}\",\n",
    "              f\"Validation Loss: {np.mean(val_losses):.4f}\")\n",
    "            \n",
    "    print(f\"Training completed in {(time.time() - start_time) / 60} min.\")\n",
    "    print(f\"Final loss: {loss}\\nValidation loss: {val_loss}\")\n",
    "    \n",
    "    return loss, val_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/6 Time taken: 1.33 min Training Loss: 0.6925 Validation Loss: 0.6922\n",
      "Epoch: 2/6 Time taken: 2.66 min Training Loss: 0.7026 Validation Loss: 0.5965\n",
      "Epoch: 3/6 Time taken: 3.93 min Training Loss: 0.3667 Validation Loss: 0.4768\n",
      "Epoch: 4/6 Time taken: 5.17 min Training Loss: 0.2841 Validation Loss: 0.4688\n",
      "Epoch: 5/6 Time taken: 6.42 min Training Loss: 0.1517 Validation Loss: 0.5004\n",
      "Epoch: 6/6 Time taken: 7.67 min Training Loss: 0.1586 Validation Loss: 0.4928\n",
      "Training completed in 7.674058783054352 min.\n",
      "Final loss: 0.15861161053180695\n",
      "Validation loss: 0.7937467098236084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586, grad_fn=<BinaryCrossEntropyBackward>),\n",
       " tensor(0.7937, grad_fn=<BinaryCrossEntropyBackward>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
